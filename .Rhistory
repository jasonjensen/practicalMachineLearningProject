confusionMatrix(data=predict(modelBoot5$finalModel, newdata=predictors), predictors$classe)
confusionMatrix(data=predict(modelBoot5, newdata=predictors), predictors$classe)
myAccTrain <- function(x){
t <- confusionMatrix(data=predict(x, newdata=predictors), predictors$classe)
#return(t$overall[1])
}
lapply(modelList, myAccTrain)
modelList <- list(modelBoot5, modelBoot6, modelBoot7)
lapply(modelList, myAccTrain)
modelList <- list(modelBoot5, modelBoot6, modelBoot7,
modelRF5, modelRF5_25, modelRF5_50)
lapply(modelList, myAccTrain)
myAccTrain <- function(x){
t <- confusionMatrix(data=predict(x, newdata=predictors), predictors$classe)
return(t$overall[1])
}
lapply(modelList, myAccTrain)
myAccTrain <- function(x){
t <- confusionMatrix(data=predict(x, newdata=predictors), predictors$classe)
return(t$overall[1])
}
myAccTest <- function(x){
t <- confusionMatrix(data=predict(x, newdata=midTest), predictors$midTest)
return(t$overall[1])
}
trainAccuracy <- lapply(modelList, myAccTrain)
testAccuracy <- lapply(modelList, myAccTest)
myAccTest <- function(x){
t <- confusionMatrix(data=predict(x, newdata=midTest), midTest$classe)
return(t$overall[1])
}
testAccuracy <- lapply(modelList, myAccTest)
overview <- c(modelList, trainAccuracy, testAccuracy)
overview
overview <- cbind(modelList, trainAccuracy, testAccuracy)
overview
overview <- cbind(names(modelList), trainAccuracy, testAccuracy)
overview
10/.6
15*25
bootControl <- trainControl(method = "boot632", number = 300)
system.time(modelBoot5_300 <- train(predictors[,1:52], predictors$classe, method="rpart", trControl = bootControl, tuneLength = 5))
system.time(modelBoot6_300 <- train(predictors[,1:52], predictors$classe, method="rpart", trControl = bootControl, tuneLength = 6))
system.time(modelBoot7_300 <- train(predictors[,1:52], predictors$classe, method="rpart",trControl = bootControl, tuneLength = 7))
modelList <- list(modelBoot5_300, modelBoot6_300, modelBoot7_300,
modelRF5, modelRF5_25, modelRF5_50)
trainAccuracy <- lapply(modelList, myAccTrain)
testAccuracy <- lapply(modelList, myAccTest)
overview <- cbind(modelList, trainAccuracy, testAccuracy)
overview
save.image("C:/Users/Jason/Box Sync/Current Projects/Coursera/machine2.RData")
system.time(modelRF5 <- train(predictors[,1:52], predictors$classe, method="rf", tuneLength = 5, verbose=TRUE, ntree = 50))
system.time(modelRF6 <- train(classe ~ ., method="rf", data=predictors, tuneLength = 6, , ntree = 50))
system.time(modelRF7 <- train(classe ~ ., method="rf", data=predictors, tuneLength = 7, , ntree = 50))
system.time(modelRF6 <- train(predictors[,1:52], predictors$classe., method="rf", data=predictors, tuneLength = 6, , ntree = 50))
system.time(modelRF7 <- train(predictors[,1:52], predictors$classe, method="rf", data=predictors, tuneLength = 7, , ntree = 50))
system.time(modelRF6 <- train(predictors[,1:52], predictors$classe, method="rf", data=predictors, tuneLength = 6, , ntree = 50))
save.image("C:/Users/Jason/Box Sync/Current Projects/Coursera/machine2.RData")
modelList <- list(modelBoot5_300, modelBoot6_300, modelBoot7_300,
modelRF5, modelRF5_25, modelRF5_50)
modelList <- list(modelBoot5_300, modelBoot6_300, modelBoot7_300,
modelRF5, modelRF6, modelRF7)
trainAccuracy <- lapply(modelList, myAccTrain)
testAccuracy <- lapply(modelList, myAccTest)
overview <- cbind(modelList, trainAccuracy, testAccuracy)
overview
modelFit <- NULL
modelFit2 <- NULL
modelList <- NULL
modelBoot5 <- NULL
modelBoot6 <- NULL
modelBoot7 <- NULL
modelRF5_25 <- NULL
modelRF5_50 <- NULL
save.image("C:/Users/Jason/Box Sync/Current Projects/Coursera/machine2.RData")
system.time(modelRF1 <- train(predictors[,1:52], predictors$classe, method="rf", tuneLength = 1, verbose=TRUE, ntree = 50))
system.time(modelRF2 <- train(predictors[,1:52], predictors$classe, method="rf", tuneLength = 2, , ntree = 50))
system.time(modelRF1 <- train(predictors[,1:52], predictors$classe, method="rf", tuneLength = 1, ntree = 25))
system.time(modelRF2 <- train(predictors[,1:52], predictors$classe, method="rf", tuneLength = 2, ntree = 25))
system.time(modelRF3 <- train(predictors[,1:52], predictors$classe, method="rf", tuneLength = 3, ntree = 25))
system.time(modelRF4 <- train(predictors[,1:52], predictors$classe, method="rf", tuneLength = 4, ntree = 25))
save.image("C:/Users/Jason/Box Sync/Current Projects/Coursera/machine2.RData")
modelList <- list(modelRF1, modelRF2, modelRF3, modelRF4,
modelRF5, modelRF6, modelRF7)
trainAccuracy <- lapply(modelList, myAccTrain)
testAccuracy <- lapply(modelList, myAccTest)
overview <- cbind(modelList, trainAccuracy, testAccuracy)
overview
bootControl <- trainControl(method = "boot632", number = 25)
system.time(modelBoot5 <- train(predictors[,1:52], predictors$classe, method="rpart", trControl = bootControl, tuneLength = 5))
modelList <- list(modelBoot5, modelBoot5_300)
trainAccuracy <- lapply(modelList, myAccTrain)
testAccuracy <- lapply(modelList, myAccTest)
overview <- cbind(modelList, trainAccuracy, testAccuracy)
overview
system.time(modelBoot10 <- train(predictors[,1:52], predictors$classe, method="rpart", trControl = bootControl, tuneLength = 10))
system.time(modelBoot15 <- train(predictors[,1:52], predictors$classe, method="rpart", trControl = bootControl, tuneLength = 15))
system.time(modelBoot20 <- train(predictors[,1:52], predictors$classe, method="rpart", trControl = bootControl, tuneLength = 20))
system.time(modelBoot25 <- train(predictors[,1:52], predictors$classe, method="rpart", trControl = bootControl, tuneLength = 25))
modelList <- list(modelBoot5, modelBoot10, modelBoot15, modelBoot20, modelBoot25)
trainAccuracy <- lapply(modelList, myAccTrain)
testAccuracy <- lapply(modelList, myAccTest)
overview <- cbind(modelList, trainAccuracy, testAccuracy)
overview
testStore <- testing
testing <- testing[,8:160] #drop variables at front
testing <- testing[,1:152] #predictor variables for preprocessing
nonConstant <- apply(testing, 2, function(x) !is.na(var(x)))
testing <- testing[,nonConstant]
nonMissing <- apply(testing, 2, function(x) sum(is.na(x)) < 19000)
testing <- testing[,nonMissing]
testing$classe <- testStore$classe
library(Hmisc)   #data exploration
library(caret)   #machine learning
library(rattle)  #tree diagram
training <- read.csv(url("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"))
testing <- read.csv(url("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"))
set.seed(254684)
inErrorEstSample <- createDataPartition(y=training$classe, p=.05, list=FALSE)
errorEstSample <- training[inErrorEstSample,]
training <- training[-inErrorEstSample,]
inMidTest <- createDataPartition(y=training$classe, p=.15, list=FALSE)
midTest <- training[inMidTest,]
training <- training[-inMidTest,]
#store copies for reference
trainingStore <- training
midTestStore <- midTest
errorEstSampleStore <- errorEstSample
testStore <- testing
myTrim <- function(df, outcome) {
df <- df[,8:159] #drop variables at front and outcome variable
nonConstant <- apply(df, 2, function(x) !is.na(var(x)))
df <- df[,nonConstant]  #drop constant variables
nonMissing <- apply(df, 2, function(x) sum(is.na(x)) < 19000)
df <- df[,nonMissing] #drop variables which are mostly missing
df$classe <- outcome #add outcome variable
return(df)
}
#apply trim to samples
training <- myTrim(training, trainingStore$casse)
midTest <- myTrim(midTest, midTestStore$casse)
errorEstSample <- myTrim(errorEstStore, errorEstStore$casse)
testing <- myTrim(testing, testing$casse)
library(Hmisc)   #data exploration
library(caret)   #machine learning
library(rattle)  #tree diagram
training <- read.csv(url("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"))
testing <- read.csv(url("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"))
#particion data into training, probe, and estimation set for Out-of-Sample errors
set.seed(254684)
inErrorEstSample <- createDataPartition(y=training$classe, p=.05, list=FALSE)
errorEstSample <- training[inErrorEstSample,]
training <- training[-inErrorEstSample,]
inMidTest <- createDataPartition(y=training$classe, p=.15, list=FALSE)
midTest <- training[inMidTest,]
training <- training[-inMidTest,]
#store copies for reference
trainingStore <- training
midTestStore <- midTest
errorEstSampleStore <- errorEstSample
testStore <- testing
myTrim <- function(df, outcome) {
df <- df[,8:159] #drop variables at front and outcome variable
nonConstant <- apply(df, 2, function(x) !is.na(var(x)))
df <- df[,nonConstant]  #drop constant variables
nonMissing <- apply(df, 2, function(x) sum(is.na(x)) < 19000)
df <- df[,nonMissing] #drop variables which are mostly missing
df$classe <- outcome #add outcome variable
return(df)
}
#apply trim to samples
training <- myTrim(training, trainingStore$casse)
midTest <- myTrim(midTest, midTestStore$casse)
errorEstSample <- myTrim(errorEstSample, errorEstSampleStore$casse)
testing <- myTrim(testing, testing$casse)
names(modelList)
name(modelList)
modelList <- list("modelBoot5" = modelBoot5,
"modelBoot10" = modelBoot10,
"modelBoot15" = modelBoot15,
"modelBoot20" = modelBoot20,
"modelBoot25" = modelBoot25,
"modelRF1" = modelRF1,
"modelRF2" = modelRF2,
"modelRF3" = modelRF3)
names(modelList)
overview <- cbind(names(modelList), trainAccuracy, testAccuracy)
overview
trainAccuracy <- lapply(modelList, myAccTrain)
testAccuracy <- lapply(modelList, myAccTest)
View(predictors)
View(errorEstSample)
View(predictors)
library(Hmisc)   #data exploration
library(caret)   #machine learning
library(rattle)  #tree diagram
training <- read.csv(url("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"))
testing <- read.csv(url("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"))
#particion data into training, probe, and estimation set for Out-of-Sample errors
set.seed(254684)
inErrorEstSample <- createDataPartition(y=training$classe, p=.05, list=FALSE)
errorEstSample <- training[inErrorEstSample,]
training <- training[-inErrorEstSample,]
inMidTest <- createDataPartition(y=training$classe, p=.15, list=FALSE)
midTest <- training[inMidTest,]
training <- training[-inMidTest,]
#store copies for reference
trainingStore <- training
midTestStore <- midTest
errorEstSampleStore <- errorEstSample
testStore <- testing
myTrim <- function(df, outcome) {
df <- df[,8:159] #drop variables at front and outcome variable
nonConstant <- apply(df, 2, function(x) !is.na(var(x)))
df <- df[,nonConstant]  #drop constant variables
nonMissing <- apply(df, 2, function(x) sum(is.na(x)) < 19000)
df <- df[,nonMissing] #drop variables which are mostly missing
df$casse <- outcome #add outcome variable
return(df)
}
training <- myTrim(training, trainingStore$casse)
midTest <- myTrim(midTest, midTestStore$casse)
errorEstSample <- myTrim(errorEstSample, errorEstSampleStore$casse)
testing <- myTrim(testing, testing$casse)
myAccTrain <- function(x){
t <- confusionMatrix(data=predict(x, newdata=predictors), predictors$classe)
return(t$overall[1])
}
myAccTest <- function(x){
t <- confusionMatrix(data=predict(x, newdata=midTest), midTest$classe)
return(t$overall[1])
}
#list of models to compare
modelList <- list("modelBoot5" = modelBoot5,
"modelBoot10" = modelBoot10,
"modelBoot15" = modelBoot15,
"modelBoot20" = modelBoot20,
"modelBoot25" = modelBoot25,
"modelRF1" = modelRF1,
"modelRF2" = modelRF2,
"modelRF3" = modelRF3)
#create accuracy estimates
trainAccuracy <- lapply(modelList, myAccTrain)
testAccuracy <- lapply(modelList, myAccTest)
View(midTest)
training <- trainingStore
training <- myTrim(training, trainingStore$casse)
View(training)
training <- trainingStore
training <- myTrim(training, outcome=trainingStore$casse)
library(Hmisc)   #data exploration
library(caret)   #machine learning
library(rattle)  #tree diagram
training <- read.csv(url("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"))
testing <- read.csv(url("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"))
#particion data into training, probe, and estimation set for Out-of-Sample errors
set.seed(254684)
inErrorEstSample <- createDataPartition(y=training$classe, p=.05, list=FALSE)
errorEstSample <- training[inErrorEstSample,]
training <- training[-inErrorEstSample,]
inMidTest <- createDataPartition(y=training$classe, p=.15, list=FALSE)
midTest <- training[inMidTest,]
training <- training[-inMidTest,]
#store copies for reference
trainingStore <- training
midTestStore <- midTest
errorEstSampleStore <- errorEstSample
testStore <- testing
myTrim <- function(df, outcome) {
df <- df[,8:159] #drop variables at front and outcome variable
nonConstant <- apply(df, 2, function(x) !is.na(var(x)))
df <- df[,nonConstant]  #drop constant variables
nonMissing <- apply(df, 2, function(x) sum(is.na(x)) < 19000)
df <- df[,nonMissing] #drop variables which are mostly missing
df$classe <- outcome #add outcome variable
return(df)
}
#apply trim to samples
training <- myTrim(training, outcome=trainingStore$classe)
midTest <- myTrim(midTest, midTestStore$classe)
errorEstSample <- myTrim(errorEstSample, errorEstSampleStore$classe)
testing <- myTrim(testing, testing$classe)
myAccTrain <- function(x){
t <- confusionMatrix(data=predict(x, newdata=training), training$classe)
return(t$overall[1])
}
myAccTest <- function(x){
t <- confusionMatrix(data=predict(x, newdata=midTest), midTest$classe)
return(t$overall[1])
}
#list of models to compare
modelList <- list("modelBoot5" = modelBoot5,
"modelBoot10" = modelBoot10,
"modelBoot15" = modelBoot15,
"modelBoot20" = modelBoot20,
"modelBoot25" = modelBoot25,
"modelRF1" = modelRF1,
"modelRF2" = modelRF2,
"modelRF3" = modelRF3)
#create accuracy estimates
trainAccuracy <- lapply(modelList, myAccTrain)
testAccuracy <- lapply(modelList, myAccTest)
#combine and view results
overview <- cbind(names(modelList), trainAccuracy, testAccuracy)
overview
confMat <- confusionMatrix(data=predict(modelRF1, newdata=errorEstSample), errorEstSample$classe)
confMat$overall[1]
estimatedOOSErrorRate <- 1 - confMat$overall[[1]]
estimatedOOSErrorRate
testPredictions <- predict(modelRF1, newdata=testing)
testingStore$classe <- testPredictions
testStore$classe <- testPredictions
View(testStore)
head(testStore)
testStore$predicted_classe <- testPredictions
head(testStore[c("user_name", "problem_id", "predicted_classe")], n=20)
save.image("C:/Users/Jason/Box Sync/Current Projects/Coursera/machine2.RData")
save.image("C:/Users/Jason/Box Sync/Current Projects/Coursera/machine2.RData")
library(Curl)
library(RCurl)
setwd("C:\\Users\\Jason\\Documents\\GitHub\\practicalMachineLearningProject")
?confusionMatrix
library(Hmisc)        #data exploration
library(caret)        #machine learning
library(rpart)        #rpart caret method
library(randomForest) #random forest caret method
training <- read.csv("pml-training.csv")
testing <- read.csv("pml-testing.csv")
#partition data into training, probe, and estimation set for Out-of-Sample errors
set.seed(254684)
inErrorEstSample <- createDataPartition(y=training$classe, p=.05, list=FALSE)
errorEstSample <- training[inErrorEstSample,]
training <- training[-inErrorEstSample,]
inMidTest <- createDataPartition(y=training$classe, p=.15, list=FALSE)
midTest <- training[inMidTest,]
training <- training[-inMidTest,]
#store copies for reference
trainingStore <- training
midTestStore <- midTest
errorEstSampleStore <- errorEstSample
testStore <- testing
myTrim <- function(df, outcome) {
df <- df[,8:159] #drop variables at front and outcome variable
nonConstant <- apply(df, 2, function(x) !is.na(var(x)))
df <- df[,nonConstant]  #drop constant variables
df$classe <- outcome #add outcome variable
return(df)
}
#apply trim to samples
training <- myTrim(training, outcome=trainingStore$classe)
midTest <- myTrim(midTest, midTestStore$classe)
errorEstSample <- myTrim(errorEstSample, errorEstSampleStore$classe)
testing <- myTrim(testing, testing$classe)
bootControl <- trainControl(method = "boot632", number = 25)
modelBoot5 <- train(training[,1:52], training$classe, method="rpart", trControl = bootControl, tuneLength = 5)
describe(trainingStore$kurtosis_yaw_belt)
tabulate(trainingStore$kurtosis_yaw_belt)
table(trainingStore$kurtosis_yaw_belt)
table(trainingStore$kurtosis_picth_belt)
var(trainingStore$kurtosis_picth_belt)
is.na(var(trainingStore$kurtosis_picth_belt))
View(training)
library(Hmisc)        #data exploration
library(caret)        #machine learning
library(rpart)        #rpart caret method
library(randomForest) #random forest caret method
training <- read.csv("pml-training.csv")
testing <- read.csv("pml-testing.csv")
#partition data into training, probe, and estimation set for Out-of-Sample errors
set.seed(254684)
inErrorEstSample <- createDataPartition(y=training$classe, p=.05, list=FALSE)
errorEstSample <- training[inErrorEstSample,]
training <- training[-inErrorEstSample,]
inMidTest <- createDataPartition(y=training$classe, p=.15, list=FALSE)
midTest <- training[inMidTest,]
training <- training[-inMidTest,]
#store copies for reference
trainingStore <- training
midTestStore <- midTest
errorEstSampleStore <- errorEstSample
testStore <- testing
myTrim <- function(df, outcome) {
df <- df[,8:159] #drop variables at front and outcome variable
nonConstant <- apply(df, 2, function(x) !is.na(var(x)))
df <- df[,nonConstant]  #drop constant variables
df$classe <- outcome #add outcome variable
return(df)
}
#apply trim to samples
training <- myTrim(training, outcome=trainingStore$classe)
midTest <- myTrim(midTest, midTestStore$classe)
errorEstSample <- myTrim(errorEstSample, errorEstSampleStore$classe)
testing <- myTrim(testing, testing$classe)
describe(trainingStore$kurtosis_picth_belt)
getTree(modelRF1, 1)
modelRF1
modelRF1$modelInfo
modelRF1$finalModel
getTree(modelRF1$finalModel, 1)
?getTree
head(getTree(modelRF1$finalModel, 1))
importance(modelRF1$finalModel)
imp <- importance(modelRF1$finalModel)
imp[order(imp$ MeanDecreaseGini),]
imp[order(imp$ MeanDecreaseGini)]
imp[order(imp$MeanDecreaseGini)]
imp[order(imp$MeanDecreaseGini),]
imp[order(MeanDecreaseGini)]
imp[order(1)]
imp[order(1:52)]
?order
sort.list(imp)
imp[sort.list(imp)]
imp[sort.list(imp, decreasing = TRUE)]
c(names(imp), imp[sort.list(imp, decreasing = TRUE)])
c(row.names(imp), imp[sort.list(imp, decreasing = TRUE)])
cbind(row.names(imp), imp[sort.list(imp, decreasing = TRUE)])
imp <- sort.list(imp, decreasing=TRUE)
imp
imp <- importance(modelRF1$finalModel)
imp <- as.data.frame(importance(modelRF1$finalModel))
View(imp)
View(imp)
impData$type <- "none"
impData <- as.data.frame(importance(modelRF1$finalModel))
impData$type <- "none"
impData$type <- ifelse(pmatch("belt", impData$row.names, "belt", impdata$type))
impData$type <- ifelse(pmatch("belt", impData$row.names, "belt", impData$type))
impData$type <- "none"
impData$type <- ifelse(pmatch("belt", impData$row.names), "belt", impData$type))
impData$type <- ifelse(pmatch("belt", impData$row.names), "belt", impData$type)
View(impData)
impData$type <- "none"
View(impData)
impData$type <- ifelse(pmatch("belt", impData$row.names), "belt", impData$type)
View(impData)
impData$row.names
names(impData)
rownames(impData)
impData$rowname <- rownames(impData)
impData$type <- "none"
impData$type <- ifelse(pmatch("belt", impData$rowname), "belt", impData$type)
View(impData)
impData$type <- "none"
impData$type <- ifelse(pmatch("belt", impData$rowname) == 1, "belt", impData$type)
View(impData)
head(impData)
impData$type <- "none"
impData$type <- ifelse(pmatch("belt", impData$rowname) >= 1, "belt", impData$type)
head(impData)
class(impData$rowname)
belt <- lapply(impData$rowname, function(x) grepl(pattern = "belt", x))
belt
impData$belt <- belt
View(impData)
impData <- as.data.frame(importance(modelRF1$finalModel))
impData$rowname <- rownames(impData)
impData$type <- "arm"
belt <- lapply(impData$rowname, function(x) grepl(pattern = "belt", x))
forearm <- lapply(impData$rowname, function(x) grepl(pattern = "forearm", x))
dumbbell <- lapply(impData$rowname, function(x) grepl(pattern = "dumbell", x))
impData$type <- ifelse(belt, "belt", impData$type)
impData$type <- ifelse(forearm, "forearm", impData$type)
impData$type <- ifelse(dumbbell, "dumbbell", impData$type)
View(impData)
impData <- as.data.frame(importance(modelRF1$finalModel))
impData$rowname <- rownames(impData)
impData$type <- "arm"
belt <- lapply(impData$rowname, function(x) grepl(pattern = "belt", x))
forearm <- lapply(impData$rowname, function(x) grepl(pattern = "forearm", x))
dumbbell <- lapply(impData$rowname, function(x) grepl(pattern = "dumbbell", x))
impData$type <- ifelse(belt, "belt", impData$type)
impData$type <- ifelse(forearm, "forearm", impData$type)
impData$type <- ifelse(dumbbell, "dumbbell", impData$type)
View(impData)
plot(impData$MeanDecreaseGini)
plot(impData$MeanDecreaseGini, color=impData$type)
plot(impData$MeanDecreaseGini, colour=impData$type)
library(ggplot2)      #plotting
qplot(impData$MeanDecreaseGini, colour=impData$type)
qplot(impData$MeanDecreaseGini, colour=impData$type, smooth="density")
qplot(impData$MeanDecreaseGini, colour=impData$type, geom="density")
qplot(impData$MeanDecreaseGini, colour=impData$type, geom="dotplot")
qplot(impData$MeanDecreaseGini, colour=impData$type, geom="dotplot", alpha = .5)
z <- ggplot(impData, aes(meanDecreaseGini, colour = factor(type))) + geom_point()
z
z <- ggplot(impData, aes(MeanDecreaseGini, colour = factor(type))) + geom_point()
z
z <- ggplot(impData, aes(MeanDecreaseGini, colour = factor(type))) + geom_dotplot()
z
z <- ggplot(impData, aes(MeanDecreaseGini, fill = factor(type))) + geom_dotplot()
z
z <- ggplot(impData, aes(MeanDecreaseGini, fill = factor(type), alpha = .5)) + geom_dotplot()
z
z <- ggplot(impData, aes(MeanDecreaseGini, fill = factor(type))) + geom_dotplot()
z
?importance
importancePlot <- ggplot(impData, aes(MeanDecreaseGini, fill = factor(type))) + geom_dotplot() + labs(title = "Importance of Variables by Sensor Location") + ylim(0, .3)
importancePlot
impData <- impData[order(impData$MeanDecreaseGini),]
importancePlot <- ggplot(impData, aes(MeanDecreaseGini, index,  fill = factor(type))) + geom_point() + labs(title = "Importance of Variables by Sensor Location") + ylim(0, .3)
importancePlot
impData$index <- [1:52]
impData$index <- 1:52
importancePlot <- ggplot(impData, aes(MeanDecreaseGini, index,  fill = factor(type))) + geom_point() + labs(title = "Importance of Variables by Sensor Location") + ylim(0, .3)
importancePlot
importancePlot <- ggplot(impData, aes(index, MeanDecreaseGini,  fill = factor(type))) + geom_point() + labs(title = "Importance of Variables by Sensor Location")
importancePlot
importancePlot <- ggplot(impData, aes(index, MeanDecreaseGini,  colour = factor(type))) + geom_point() + labs(title = "Importance of Variables by Sensor Location")
importancePlot
importancePlot <- ggplot(impData, aes(index, MeanDecreaseGini,  colour = factor(type), size= MeanDecreaseGini)) + geom_point() + labs(title = "Importance of Variables by Sensor Location")
importancePlot
